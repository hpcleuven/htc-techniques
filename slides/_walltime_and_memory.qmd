# Walltime & memory


## How long will your job run?

## Running example

R script `dgemm.R`

- takes argument $N$ and $p$
- generates matrix $A \in \mathbb{R}^{N \times N}$, elements normally distributed
- computes $A^p$
- determines minimum and maximum diagonal element

<!-- . . . -->

```{.bash}
Rscript dgemm.R  --size 1000  --power 15
```


##  Benchmark job script

```{.bash filename=memory_and_walltime.slurm}
#!/usr/bin/env -S bash -l
#SBATCH --account=lpt2_sysadmin
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=1
#SBATCH --time=01:00:00
#SBATCH --partition=batch_sapphirerapids
#SBATCH --cluster=wice

module load R/4.4.0-gfbf-2023a
module load GCCcore/12.3.0

Rscript dgemm.R --size $SIZE --power $POWER   # <1>
```

1. Note `SIZE` and `POWER` environment variables


## Running benchmark

Submit with range of values for `SIZE` and `POWER`, e.g.,

```{.bash}
$ sbatch  --export=ALL,SIZE=5000,POWER=10  memory_and_walltime.slurm
$ sbatch  --export=ALL,SIZE=5000,POWER=20  memory_and_walltime.slurm
$ sbatch  --export=ALL,SIZE=5000,POWER=40  memory_and_walltime.slurm
$ sbatch  --export=ALL,SIZE=10000,POWER=10  memory_and_walltime.slurm
$ sbatch  --export=ALL,SIZE=10000,POWER=20  memory_and_walltime.slurm
$ sbatch  --export=ALL,SIZE=10000,POWER=40  memory_and_walltime.slurm
...
```

. . .

When job, e.g., 62199204, finished, use `sacct`
```bash
$ sacct  --cluster=wice  --jobs=62199204.batch  --format=jobid,elapsed
```


## Walltime benchmark results

::::: {.columns}
:::: {.column width=50%}
::: {style="font-size: 70%;"}
| job ID   | $N$     | $p$     | walltime |
|----------|---------|---------|----------|
| 62199204 | 5000    | 10      | 00:02:17 |
| 62199205 | 5000    | 20      | 00:04:36 |
| 62199206 | 5000    | 40      | 00:08:50 |
| 62199207 | 10000   | 10      | 00:15:10 |
| 62199208 | 10000   | 20      | 00:30:57 |
| 62199209 | 10000   | 40      | 01:00:15 |
| 62199210 | 20000   | 10      | 00:04:19 |
| 62199211 | 20000   | 20      | 00:04:24 |
| 62199212 | 20000   | 40      | 00:04:34 |
| 62199213 | 50000   | 10      | 00:00:55 |
| 62199214 | 50000   | 20      | 00:00:45 |
| 62199215 | 50000   | 40      | 00:00:44 |
:::
::::
:::: {.column width=50% .fragment .incremental}
- $T(N, p) \propto p$
- $T(N, p) \propto N^3$
- What happened for $N = 10000$, $p = 40$?
- What happend for $N = 20000$ and $N = 50000$?
::::
:::::


## Out of time

Inspect output for job 62199209

```bash
...
Walltime: 00-01:00:00
========================================================================

Lmod is automatically replacing "cluster/genius/login" with
"cluster/wice/batch_sapphirerapids".

slurmstepd: error: *** JOB 62199209 ON q16c03n1 CANCELLED
AT 2024-08-13T18:28:16 DUE TO TIME LIMIT ***  # <1>
```

1. Oopsie: walltime exceeded requested walltime

::: {.callout-warning .fragment}
No output, 1 hour of computime lost!
:::


## What about $N$ = 20000, 50000

::: {style="font-size: 70%;"}
| job ID   | $N$     | $p$     | walltime |
|----------|---------|---------|----------|
| 62199210 | 20000   | 10      | 00:04:19 |
| 62199211 | 20000   | 20      | 00:04:24 |
| 62199212 | 20000   | 40      | 00:04:34 |
| 62199213 | 50000   | 10      | 00:00:55 |
| 62199214 | 50000   | 20      | 00:00:45 |
| 62199215 | 50000   | 40      | 00:00:44 |
:::

```{.bash .fragment}
...
Walltime: 00-01:00:00
========================================================================
...
slurmstepd: error: Detected 1 oom_kill event in StepId=62199210.batch.
Some of the step tasks have been OOM Killed.                            # <1>
```

1. Oopsie, Out Of Memory (OOM)

::: notes
Initializing the matrix $A$ still succeeds for $N = 20000$, and
takes approximately 260 seconds.
:::


## Memory

*Check* RAM of node in [VSCdocs](https://docs.vscentrum.be/hardware.html),
typically 256 GB

::: {.incremental style="font-size: 85%;"}
- Total memory for job
  - specify with `--mem`, e.g.,
    ```bash
    #SBATCH --mem=10G
    ```
  - `--mem` < RAM - 8 GB
- Memory per CPU
  - specify with `--mem-per-cpu`, e.g.,
    ```bash
    #SBATCH --mem-per-cpu=5G
    ```
  - `--mem-per-cpu` $\times$ `--cpus-per-task` $\times$ `--ntasks` < RAM - 8 GB
:::

::: {.fragment}
Units: `K`, `M`, `G`, `T`
:::


## How much memory do you need?

::: {.incremental}
- Specify memory (`--mem=30G`)
- But how much?
  - Don't underestimate!
  - Don't (massively) overestimate
- Experiment
  - Start with "small" problem
  - Increase problem size gradually
  - Extrapolate to real problem
:::


## How much was used?

Submit with range of values for `SIZE` and `POWER`, e.g.,

```{.bash}
$ sbatch  --export=ALL,SIZE=5000,POWER=10  memory_and_walltime.slurm
$ sbatch  --export=ALL,SIZE=5000,POWER=20  memory_and_walltime.slurm
...
```

. . .

When job, e.g., 62199204, finished, use `sacct`
```bash
$ sacct  --cluster=wice  --jobs=62199204.batch  \
         --format=jobid,maxrss,maxvmsize
```

. . .

::: {.callout-tip}
Combine walltime and memory benchmark!
:::


## Memory benchmark results

::::: {.columns}
:::: {.column width=50%}
::: {style="font-size: 70%;"}
| job ID   | $N$   | $p$ | $M$ (GB)    |
|----------|-------|-----|-------------|
| 62204487 | 5000  | 10  |   0.82      |
| 62204488 | 5000  | 20  |   1.01      |
| 62204489 | 5000  | 40  |   0.82      |
| 62204490 | 10000 | 10  |   3.81      |
| 62204491 | 10000 | 20  |   3.82      |
| 62204492 | 10000 | 40  |   3.82      |
| 62204493 | 20000 | 10  |  14.61      |
| 62204494 | 20000 | 20  |  12.03      |
| 62204495 | 20000 | 40  |  12.03      |
:::
::::
:::: {.column width=50% .fragment .incremental}
- $M(N, p) \propto N^2$
- $M(N, p)$ constant in $p$
::::
:::::


## Summary walltime & memory

*Do not underestimate!*

::: {.callout-warning}
You will waste resource
:::

. . .

Benchmark for walltime and memory

::: {.callout-warning}
Unless cost of benchmarking is higher than production cost
:::
